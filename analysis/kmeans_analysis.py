import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√µes de visualiza√ß√£o
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

print("=" * 70)
print("AN√ÅLISE DE CLUSTERING K-MEANS - DATASET HOUSES")
print("=" * 70)

# ====================================================
# 1. CARREGAMENTO E PREPARA√á√ÉO DOS DADOS
# ====================================================
print("\n" + "=" * 70)
print("1. CARREGAMENTO E PREPARA√á√ÉO DOS DADOS")
print("=" * 70)

# Carregar dataset
df = pd.read_csv('./houses.csv')
print(f"‚úì Dataset carregado: {df.shape[0]} linhas, {df.shape[1]} colunas")

# Converter colunas yes/no para 1/0
colunas_binarias = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 
                    'airconditioning', 'prefarea']

for col in colunas_binarias:
    df[col] = df[col].map({'yes': 1, 'no': 0})

# Codificar furnishingstatus
furnishing_map = {'unfurnished': 0, 'semi-furnished': 1, 'furnished': 2}
df['furnishingstatus_encoded'] = df['furnishingstatus'].map(furnishing_map)

# Selecionar features num√©ricas para clustering
features_clustering = ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 
                       'mainroad', 'guestroom', 'basement', 'hotwaterheating',
                       'airconditioning', 'parking', 'prefarea', 'furnishingstatus_encoded']

X = df[features_clustering].copy()
print(f"‚úì Features selecionadas: {len(features_clustering)}")
print(f"‚úì Shape dos dados: {X.shape}")

# ====================================================
# 2. NORMALIZA√á√ÉO DOS DADOS
# ====================================================
print("\n" + "=" * 70)
print("2. NORMALIZA√á√ÉO DOS DADOS (STANDARDSCALER)")
print("=" * 70)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
print("‚úì Dados normalizados (m√©dia=0, desvio padr√£o=1)")
print(f"‚úì Shape dos dados normalizados: {X_scaled.shape}")

# ====================================================
# 3. M√âTODO DO COTOVELO (ELBOW METHOD)
# ====================================================
print("\n" + "=" * 70)
print("3. DETERMINA√á√ÉO DO N√öMERO IDEAL DE CLUSTERS")
print("=" * 70)

print("\nüìä Calculando M√©todo do Cotovelo...")
K_range = range(2, 11)
inertias = []
silhouette_scores = []
davies_bouldin_scores = []
calinski_harabasz_scores = []

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_scaled)
    
    inertias.append(kmeans.inertia_)
    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))
    davies_bouldin_scores.append(davies_bouldin_score(X_scaled, kmeans.labels_))
    calinski_harabasz_scores.append(calinski_harabasz_score(X_scaled, kmeans.labels_))

# Criar figura com m√∫ltiplos gr√°ficos
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Gr√°fico 1: M√©todo do Cotovelo
axes[0, 0].plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)
axes[0, 0].set_xlabel('N√∫mero de Clusters (k)', fontsize=12)
axes[0, 0].set_ylabel('In√©rcia (WCSS)', fontsize=12)
axes[0, 0].set_title('M√©todo do Cotovelo', fontsize=14, fontweight='bold')
axes[0, 0].grid(True, alpha=0.3)

# Gr√°fico 2: Silhouette Score
axes[0, 1].plot(K_range, silhouette_scores, 'go-', linewidth=2, markersize=8)
axes[0, 1].set_xlabel('N√∫mero de Clusters (k)', fontsize=12)
axes[0, 1].set_ylabel('Silhouette Score', fontsize=12)
axes[0, 1].set_title('Coeficiente de Silhueta (maior √© melhor)', fontsize=14, fontweight='bold')
axes[0, 1].grid(True, alpha=0.3)
axes[0, 1].axhline(y=0.5, color='r', linestyle='--', label='Threshold 0.5')
axes[0, 1].legend()

# Gr√°fico 3: Davies-Bouldin Score
axes[1, 0].plot(K_range, davies_bouldin_scores, 'ro-', linewidth=2, markersize=8)
axes[1, 0].set_xlabel('N√∫mero de Clusters (k)', fontsize=12)
axes[1, 0].set_ylabel('Davies-Bouldin Score', fontsize=12)
axes[1, 0].set_title('Davies-Bouldin Index (menor √© melhor)', fontsize=14, fontweight='bold')
axes[1, 0].grid(True, alpha=0.3)

# Gr√°fico 4: Calinski-Harabasz Score
axes[1, 1].plot(K_range, calinski_harabasz_scores, 'mo-', linewidth=2, markersize=8)
axes[1, 1].set_xlabel('N√∫mero de Clusters (k)', fontsize=12)
axes[1, 1].set_ylabel('Calinski-Harabasz Score', fontsize=12)
axes[1, 1].set_title('Calinski-Harabasz Index (maior √© melhor)', fontsize=14, fontweight='bold')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('kmeans_elbow_analysis.png', dpi=300, bbox_inches='tight')
print("‚úì Gr√°fico salvo: 'kmeans_elbow_analysis.png'")

# Mostrar m√©tricas
print("\nüìà M√âTRICAS POR N√öMERO DE CLUSTERS:")
print("-" * 70)
print(f"{'K':>3} {'In√©rcia':>15} {'Silhouette':>12} {'Davies-Bouldin':>16} {'Calinski-Harabasz':>18}")
print("-" * 70)
for i, k in enumerate(K_range):
    print(f"{k:>3} {inertias[i]:>15.2f} {silhouette_scores[i]:>12.4f} "
          f"{davies_bouldin_scores[i]:>16.4f} {calinski_harabasz_scores[i]:>18.2f}")

# Determinar k ideal baseado em silhouette score
k_ideal = K_range[silhouette_scores.index(max(silhouette_scores))]
print(f"\n‚úì K ideal (baseado em Silhouette Score): {k_ideal}")

# ====================================================
# 4. TREINAMENTO DO MODELO K-MEANS
# ====================================================
print("\n" + "=" * 70)
print(f"4. TREINAMENTO DO MODELO K-MEANS (K={k_ideal})")
print("=" * 70)

kmeans_final = KMeans(n_clusters=k_ideal, random_state=42, n_init=10)
df['cluster'] = kmeans_final.fit_predict(X_scaled)

print(f"‚úì Modelo treinado com {k_ideal} clusters")
print(f"‚úì Silhouette Score: {silhouette_score(X_scaled, df['cluster']):.4f}")
print(f"‚úì Davies-Bouldin Score: {davies_bouldin_score(X_scaled, df['cluster']):.4f}")
print(f"‚úì Calinski-Harabasz Score: {calinski_harabasz_score(X_scaled, df['cluster']):.2f}")

# Distribui√ß√£o dos clusters
print("\nüìä DISTRIBUI√á√ÉO DOS CLUSTERS:")
print("-" * 70)
cluster_counts = df['cluster'].value_counts().sort_index()
for cluster, count in cluster_counts.items():
    percentage = (count / len(df)) * 100
    print(f"Cluster {cluster}: {count} casas ({percentage:.2f}%)")

# ====================================================
# 5. AN√ÅLISE DOS CLUSTERS
# ====================================================
print("\n" + "=" * 70)
print("5. CARACTER√çSTICAS DOS CLUSTERS")
print("=" * 70)

# Estat√≠sticas por cluster
cluster_stats = df.groupby('cluster')[['price', 'area', 'bedrooms', 'bathrooms', 
                                        'stories', 'parking']].mean()

print("\nüìã M√âDIAS POR CLUSTER:")
print("-" * 70)
print(cluster_stats.to_string())

# Criar tabela de perfil dos clusters
cluster_profiles = []
for cluster in range(k_ideal):
    cluster_data = df[df['cluster'] == cluster]
    profile = {
        'Cluster': cluster,
        'Tamanho': len(cluster_data),
        '% Total': f"{(len(cluster_data)/len(df)*100):.1f}%",
        'Pre√ßo M√©dio': f"R$ {cluster_data['price'].mean():,.2f}",
        '√Årea M√©dia': f"{cluster_data['area'].mean():.0f} ft¬≤",
        'Quartos M√©dio': f"{cluster_data['bedrooms'].mean():.1f}",
        'Banheiros M√©dio': f"{cluster_data['bathrooms'].mean():.1f}",
        'Ar-Cond. %': f"{(cluster_data['airconditioning'].mean()*100):.0f}%",
        'Garagem M√©dia': f"{cluster_data['parking'].mean():.1f}"
    }
    cluster_profiles.append(profile)

df_profiles = pd.DataFrame(cluster_profiles)
print("\n" + "=" * 70)
print("üìä PERFIL DETALHADO DOS CLUSTERS:")
print("=" * 70)
print(df_profiles.to_string(index=False))

# Salvar perfis em CSV
df_profiles.to_csv('cluster_profiles.csv', index=False, encoding='utf-8-sig')
print("\n‚úì Perfis salvos em 'cluster_profiles.csv'")

# ====================================================
# 6. VISUALIZA√á√ÉO DOS CLUSTERS (PCA)
# ====================================================
print("\n" + "=" * 70)
print("6. VISUALIZA√á√ÉO DOS CLUSTERS (REDU√á√ÉO DIMENSIONAL PCA)")
print("=" * 70)

# Aplicar PCA para reduzir a 2 dimens√µes
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

print(f"‚úì PCA aplicado: {X_scaled.shape[1]}D ‚Üí 2D")
print(f"‚úì Vari√¢ncia explicada PC1: {pca.explained_variance_ratio_[0]*100:.2f}%")
print(f"‚úì Vari√¢ncia explicada PC2: {pca.explained_variance_ratio_[1]*100:.2f}%")
print(f"‚úì Vari√¢ncia total explicada: {sum(pca.explained_variance_ratio_)*100:.2f}%")

# Criar visualiza√ß√£o
fig, axes = plt.subplots(1, 2, figsize=(18, 7))

# Gr√°fico 1: Scatter plot dos clusters
scatter = axes[0].scatter(X_pca[:, 0], X_pca[:, 1], 
                         c=df['cluster'], 
                         cmap='viridis', 
                         s=50, 
                         alpha=0.6,
                         edgecolors='k',
                         linewidth=0.5)

# Plotar centroides
centroids_pca = pca.transform(kmeans_final.cluster_centers_)
axes[0].scatter(centroids_pca[:, 0], centroids_pca[:, 1], 
               c='red', 
               marker='X', 
               s=300, 
               edgecolors='black',
               linewidth=2,
               label='Centroides')

axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', fontsize=12)
axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', fontsize=12)
axes[0].set_title('Visualiza√ß√£o dos Clusters (PCA)', fontsize=14, fontweight='bold')
axes[0].legend()
axes[0].grid(True, alpha=0.3)
plt.colorbar(scatter, ax=axes[0], label='Cluster')

# Gr√°fico 2: Boxplot de pre√ßos por cluster
df_plot = df[['cluster', 'price']].copy()
df_plot['cluster'] = df_plot['cluster'].astype(str)
sns.boxplot(data=df_plot, x='cluster', y='price', ax=axes[1], palette='viridis')
axes[1].set_xlabel('Cluster', fontsize=12)
axes[1].set_ylabel('Pre√ßo (R$)', fontsize=12)
axes[1].set_title('Distribui√ß√£o de Pre√ßos por Cluster', fontsize=14, fontweight='bold')
axes[1].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('kmeans_clusters_visualization.png', dpi=300, bbox_inches='tight')
print("\n‚úì Visualiza√ß√£o salva: 'kmeans_clusters_visualization.png'")

# ====================================================
# 7. HEATMAP DE CARACTER√çSTICAS DOS CLUSTERS
# ====================================================
print("\n" + "=" * 70)
print("7. HEATMAP DE CARACTER√çSTICAS")
print("=" * 70)

# Normalizar caracter√≠sticas para o heatmap
cluster_stats_normalized = df.groupby('cluster')[features_clustering].mean()

fig, ax = plt.subplots(figsize=(14, 8))
sns.heatmap(cluster_stats_normalized.T, 
            annot=True, 
            fmt='.2f', 
            cmap='RdYlGn',
            center=0,
            cbar_kws={'label': 'Valor Normalizado'},
            linewidths=0.5,
            ax=ax)

ax.set_xlabel('Cluster', fontsize=12)
ax.set_ylabel('Features', fontsize=12)
ax.set_title('Heatmap de Caracter√≠sticas M√©dias por Cluster', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.savefig('kmeans_features_heatmap.png', dpi=300, bbox_inches='tight')
print("‚úì Heatmap salvo: 'kmeans_features_heatmap.png'")

# ====================================================
# 8. INTERPRETA√á√ÉO DOS CLUSTERS
# ====================================================
print("\n" + "=" * 70)
print("8. INTERPRETA√á√ÉO DOS CLUSTERS")
print("=" * 70)

# An√°lise autom√°tica de perfis
interpretations = []
for cluster in range(k_ideal):
    cluster_data = df[df['cluster'] == cluster]
    
    avg_price = cluster_data['price'].mean()
    avg_area = cluster_data['area'].mean()
    avg_bedrooms = cluster_data['bedrooms'].mean()
    aircon_pct = cluster_data['airconditioning'].mean() * 100
    
    # Determinar perfil
    if avg_price < df['price'].quantile(0.33):
        price_level = "Econ√¥micas"
    elif avg_price < df['price'].quantile(0.67):
        price_level = "M√©dias"
    else:
        price_level = "Luxo"
    
    if avg_area < df['area'].quantile(0.33):
        size_level = "Compactas"
    elif avg_area < df['area'].quantile(0.67):
        size_level = "Padr√£o"
    else:
        size_level = "Espa√ßosas"
    
    interpretation = {
        'Cluster': cluster,
        'Classifica√ß√£o': f"{price_level} / {size_level}",
        'Descri√ß√£o': f"Casas {price_level.lower()}, {size_level.lower()}, ~{avg_bedrooms:.0f} quartos",
        'Caracter√≠sticas': f"Ar-cond: {aircon_pct:.0f}%, √Årea: {avg_area:.0f}ft¬≤"
    }
    interpretations.append(interpretation)

df_interpretations = pd.DataFrame(interpretations)
print("\nüè† PERFIL E INTERPRETA√á√ÉO:")
print("-" * 70)
print(df_interpretations.to_string(index=False))

# ====================================================
# 9. SALVAR DATASET COM CLUSTERS
# ====================================================
print("\n" + "=" * 70)
print("9. SALVANDO RESULTADOS")
print("=" * 70)

df_output = df.copy()
df_output.to_csv('houses_with_clusters.csv', index=False, encoding='utf-8-sig')
print("‚úì Dataset com clusters salvo: 'houses_with_clusters.csv'")

# Salvar interpreta√ß√µes
df_interpretations.to_csv('cluster_interpretations.csv', index=False, encoding='utf-8-sig')
print("‚úì Interpreta√ß√µes salvas: 'cluster_interpretations.csv'")

# ====================================================
# RESUMO FINAL
# ====================================================
print("\n" + "=" * 70)
print("‚úÖ AN√ÅLISE K-MEANS CONCLU√çDA!")
print("=" * 70)

print(f"""
üìä RESUMO:
  ‚Ä¢ N√∫mero de clusters: {k_ideal}
  ‚Ä¢ Silhouette Score: {silhouette_score(X_scaled, df['cluster']):.4f}
  ‚Ä¢ Total de casas analisadas: {len(df)}
  ‚Ä¢ Features utilizadas: {len(features_clustering)}
  
üìÅ ARQUIVOS GERADOS:
  ‚Ä¢ kmeans_elbow_analysis.png - An√°lise do m√©todo do cotovelo
  ‚Ä¢ kmeans_clusters_visualization.png - Visualiza√ß√£o dos clusters
  ‚Ä¢ kmeans_features_heatmap.png - Heatmap de caracter√≠sticas
  ‚Ä¢ houses_with_clusters.csv - Dataset com labels de clusters
  ‚Ä¢ cluster_profiles.csv - Perfis detalhados dos clusters
  ‚Ä¢ cluster_interpretations.csv - Interpreta√ß√£o dos clusters

üí° APLICA√á√ïES:
  ‚Ä¢ Segmenta√ß√£o de mercado imobili√°rio
  ‚Ä¢ Estratifica√ß√£o de pre√ßos
  ‚Ä¢ An√°lise de perfis de compradores
  ‚Ä¢ Recomenda√ß√£o de im√≥veis similares
""")

print("=" * 70)
